{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on data such that there are 175 events with n tracks for n in [1,25].\n",
    "# Testing on the RAMP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Daniel Zurawski\n",
    "# Author: Keshav Kapoor\n",
    "# Organization: Fermilab\n",
    "# Grammar: Python 3.6.1\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "### Choose either (1) or (2).\n",
    "### (1) If you prefer a separate window for plots, uncomment the below.\n",
    "#import matplotlib\n",
    "#matplotlib.use('qt5agg')\n",
    "\n",
    "### (2) If you prefer plots to display within the notebook, uncomment the below.\n",
    "### WARNING: Plots suffer performance issues and will lag a bit.\n",
    "%matplotlib notebook\n",
    "\n",
    "import keras # Neural network models\n",
    "import pandas as pd # Data frames\n",
    "import numpy as np  # numerical python\n",
    "from tracker3d import loader, utils, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data From .csv Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order   = (\"r\", \"phi\", \"z\")\n",
    "n_noise = 0\n",
    "code    = (order[0][0] + order[1][0] + order[2][0]).upper()\n",
    "\n",
    "# True if you want to load from .npz file. False if you want to create your own data.\n",
    "# This will NOT load from any .npz file. It will only load from .npz files stored using the\n",
    "# loader.to_file() function.\n",
    "load_from_file = True\n",
    "\n",
    "# Name of files to save/load train and target data to/from.\n",
    "test_file  = \"datasets/npz/RAMP-{0}-{1}N.npz\".format(code, n_noise)  # Data to test models with.\n",
    "train_file = \"datasets/npz/UNIF-25T-175E-{0}-{1}N.npz\".format(code, n_noise)  # Data to train models with.\n",
    "\n",
    "# Name of .csv files to load train and target data from if you don't want to load from .npz file.\n",
    "test_csv  = \"datasets/raw/RAMP-Z.csv\"\n",
    "train_csv = \"datasets/raw/UNIF-25T-175E.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data.\n",
    "if load_from_file:  # Much faster than creating your own!\n",
    "    test_data,  test_target  = loader.from_file(test_file)\n",
    "    train_data, train_target = loader.from_file(train_file)\n",
    "else:\n",
    "    # If load_from_file is False, load the data from .csv files and then save the data to .npz files.\n",
    "    train_data, train_target = loader.from_frame(\n",
    "            frame=pd.read_csv(train_csv),\n",
    "            order=order,\n",
    "            n_noise=n_noise\n",
    "    )\n",
    "    \n",
    "    permutation  = np.random.permutation(train_data.shape[0])\n",
    "    train_data   = train_data[permutation]\n",
    "    train_target = train_target[permutation]\n",
    "    \n",
    "    test_data, test_target = loader.from_frame(\n",
    "            frame=pd.read_csv(test_csv),\n",
    "            order=order,\n",
    "            n_noise=n_noise,\n",
    "            preferred_rows=train_target.shape[1],\n",
    "            preferred_tracks=train_target.shape[2]\n",
    "    )\n",
    "    loader.to_file(train_data, train_target, train_file)\n",
    "    loader.to_file(test_data, test_target, test_file)\n",
    "    \n",
    "print(\"Successfully loaded!\")\n",
    "print(\"train_data shape:   {0},\\ntrain_target shape: {1}\".format(train_data.shape, train_target.shape))\n",
    "print(\"test_data shape:    {0},\\ntest_target shape:  {1}\".format(test_data.shape, test_target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be used when we define our model.\n",
    "from keras.layers import TimeDistributed, Dense, LSTM, Activation\n",
    "from keras.layers import Dropout, GRU, Bidirectional, Conv2D, Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is time to define parameters for the model.\n",
    "input_shape  = train_data.shape[1:] # Shape of an event.\n",
    "num_classes  = train_target.shape[2] # Number of tracks per event\n",
    "epochs       = 128\n",
    "batch_size   = 64\n",
    "valsplit     = 1/8\n",
    "opt          = keras.optimizers.RMSprop(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Model's Definition and Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Input Layer #\n",
    "###############\n",
    "model = Sequential()\n",
    "model.add(Dropout(rate=1/16, input_shape=input_shape))\n",
    "\n",
    "#################\n",
    "# Hidden Layers #\n",
    "#################\n",
    "for _ in range(3):\n",
    "    model.add(Bidirectional(\n",
    "        GRU(\n",
    "            units=300, \n",
    "            return_sequences=True,\n",
    "            recurrent_dropout=1/8,\n",
    "            #activation=\"tanh\",\n",
    "            dropout=1/8,\n",
    "            implementation=2\n",
    "        ),\n",
    "        merge_mode=\"concat\"\n",
    "    ))\n",
    "################\n",
    "# Output Layer #\n",
    "################\n",
    "model.add(TimeDistributed(Dense(\n",
    "    units=num_classes,\n",
    "    kernel_initializer=\"uniform\", \n",
    "    activation=\"softmax\"\n",
    ")))\n",
    "\n",
    "###############\n",
    "# Compilation #\n",
    "###############\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# Print a summary of the model.\n",
    "print(\"Epochs: {0}, Batch Size: {1}, Validation Split {2}%\".format(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    valsplit * 100\n",
    "))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Model with the Uniform Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit (\n",
    "    train_data,\n",
    "    train_target,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_split=valsplit,\n",
    ")\n",
    "model.save(\"models/TRAIN-U25T175E-TEST-RAMP-{0}-{1}N.h5\".format(code, n_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = metrics.accuracy_vs_tracks_boxplot(guesses, test_target, noise=(n_noise > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [i / 10 for i in range(0, 1 + 10)]\n",
    "# Variation 1: Probability that hit was predicted correctly with certainty greater than or equal to threshold.\n",
    "# Variation 2: Probability that hit was predicted incorrectly with certainty greater than or equal to threshold.\n",
    "# Variation 3: Probability that hit was predicted to multiple tracks with certainties greater than or equal to threshold.\n",
    "# Variation 4: Probability that hit was predicted to no track with certainty greater than or equal to threshold.\n",
    "_ = metrics.threshold_boxplot(guesses, test_target, thresholds, variation=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_number = np.random.randint(train_data.shape[0])\n",
    "plot = utils.plot3d(\n",
    "    train_data[event_number],\n",
    "    train_target[event_number],\n",
    "    order=order,\n",
    "    title=\"Train Uniform {}\".format(event_number),\n",
    "    flat_ax=None,\n",
    "    has_noise=(n_noise > 0)\n",
    ")\n",
    "plot = utils.plot3d(\n",
    "    train_data[event_number],\n",
    "    train_target[event_number],\n",
    "    order=order,\n",
    "    title=\"Train Uniform {}\".format(event_number),\n",
    "    flat_ax=\"z\",\n",
    "    has_noise=(n_noise > 0)\n",
    ")\n",
    "#utils.display_side_by_side(train_data[event_number], train_target[event_number], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.graph_losses([(\"history\", hist)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
