{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on 125,000 events. Testing on the RAMP set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 30 03:49:33 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 0000:04:00.0     Off |                  N/A |\n",
      "| 27%   36C    P2    37W / 180W |    617MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 1080    Off  | 0000:05:00.0     Off |                  N/A |\n",
      "| 27%   34C    P8     9W / 180W |   5637MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 1080    Off  | 0000:06:00.0     Off |                  N/A |\n",
      "| 27%   34C    P2    37W / 180W |    740MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 1080    Off  | 0000:07:00.0     Off |                  N/A |\n",
      "| 27%   31C    P8     9W / 180W |    557MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 1080    Off  | 0000:0B:00.0     Off |                  N/A |\n",
      "| 27%   33C    P8     9W / 180W |      2MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 1080    Off  | 0000:0C:00.0     Off |                  N/A |\n",
      "| 27%   36C    P8     9W / 180W |   7822MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 1080    Off  | 0000:0D:00.0     Off |                  N/A |\n",
      "| 27%   35C    P8    10W / 180W |      2MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 1080    Off  | 0000:0E:00.0     Off |                  N/A |\n",
      "| 27%   33C    P8    10W / 180W |    321MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID  Type  Process name                               Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:0D:00.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "%matplotlib notebook\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import sys\n",
    "from keras.layers import TimeDistributed, Dense, Dropout, GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from tracker import extractor as ext, utils, metrics, visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train takes up 1043560 bytes.\n",
      "Test takes up 30120 bytes.\n",
      "Train is list of 125000 events.\n",
      "Test is list of 3600 events.\n",
      "CPU times: user 47.1 s, sys: 9.8 s, total: 56.9 s\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelpath   = \"data/models/UNIF-10N-25T-5000E-235R.h5\"\n",
    "trainpath   = \"data/sets/UNIF-10N-25T-125000E-235R.gz\"\n",
    "testpath    = \"data/sets/RAMP-10N-25T3600E-235R.gz\"\n",
    "train_frame = pd.read_csv(trainpath)\n",
    "test_frame  = pd.read_csv(testpath)\n",
    "train       = utils.list_of_groups(train_frame, group=\"event_id\")\n",
    "test        = utils.list_of_groups(test_frame,  group=\"event_id\")\n",
    "print(\"Train takes up {} bytes.\".format(sys.getsizeof(train)))\n",
    "print(\"Test takes up {} bytes.\".format(sys.getsizeof(test)))\n",
    "print(\"Train is list of {} events.\".format(len(train)))\n",
    "print(\"Test is list of {} events.\".format(len(test)))\n",
    "if (not utils.is_prepared(train_frame)) or (not utils.is_prepared(test_frame)):\n",
    "    print(\"Warning: frame is not prepared.\")\n",
    "    print(\"Look at the prepare_frame() function in tracker/extractor.py\")\n",
    "else:\n",
    "    del train_frame\n",
    "    del test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order = [\"phi\", \"r\", \"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an example of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 8881 #np.random.randint(len(train))\n",
    "print(\"Train {}\".format(n))\n",
    "print(\"Number of Hits: {}\".format(metrics.number_of_hits(train[n])))\n",
    "print(\"Number of Tracks: {}\".format(metrics.number_of_tracks(train[n])))\n",
    "visuals.Plot2D(train[n], order).plot(mode=\"xy\", title=\"Train {}\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape  = (235, 3)\n",
    "n_categories = 25 + 2\n",
    "optimizer    = keras.optimizers.RMSprop(lr=0.001)\n",
    "histories    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "# If you have already created a model, run this cell to load the model.\n",
    "# Else, just run the cell below this cell.\n",
    "model = keras.models.load_model(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(\n",
    "    GRU(units=256, return_sequences=True, recurrent_dropout=1/2, implementation=2),\n",
    "    merge_mode=\"mul\",\n",
    "    input_shape=input_shape))\n",
    "model.add(Dropout(rate=1/2))\n",
    "model.add(Bidirectional(\n",
    "    GRU(units=256, return_sequences=True, recurrent_dropout=1/2, implementation=2),\n",
    "    merge_mode=\"mul\"))\n",
    "model.add(Dropout(rate=1/2))\n",
    "model.add(Bidirectional(\n",
    "    GRU(units=256, return_sequences=True, recurrent_dropout=1/2, implementation=2),\n",
    "    merge_mode=\"mul\"))\n",
    "model.add(Dropout(rate=1/2))\n",
    "model.add(TimeDistributed(Dense(units=n_categories, kernel_initializer=\"uniform\", activation=\"softmax\")))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1250/1250 [==============================] - 1715s - loss: 0.4571 - acc: 0.8466 - val_loss: 0.2192 - val_acc: 0.9363\n",
      "Epoch 2/128\n",
      "1250/1250 [==============================] - 1681s - loss: 0.4472 - acc: 0.8511 - val_loss: 0.2186 - val_acc: 0.9365\n",
      "Epoch 3/128\n",
      "1250/1250 [==============================] - 1674s - loss: 0.4583 - acc: 0.8485 - val_loss: 0.2263 - val_acc: 0.9334\n",
      "Epoch 4/128\n",
      "1250/1250 [==============================] - 1670s - loss: 0.4742 - acc: 0.8435 - val_loss: 0.2180 - val_acc: 0.9357\n",
      "Epoch 5/128\n",
      "1250/1250 [==============================] - 1665s - loss: 0.4556 - acc: 0.8512 - val_loss: 0.2202 - val_acc: 0.9357\n",
      "Epoch 6/128\n",
      "1250/1250 [==============================] - 1668s - loss: 0.4421 - acc: 0.8565 - val_loss: 0.2186 - val_acc: 0.9367\n",
      "Epoch 7/128\n",
      "1250/1250 [==============================] - 1668s - loss: 0.4335 - acc: 0.8603 - val_loss: 0.2123 - val_acc: 0.9381\n",
      "Epoch 8/128\n",
      "1250/1250 [==============================] - 1665s - loss: 0.4358 - acc: 0.8598 - val_loss: 0.2196 - val_acc: 0.9363\n",
      "Epoch 9/128\n",
      "1250/1250 [==============================] - 1666s - loss: 0.4592 - acc: 0.8524 - val_loss: 0.2167 - val_acc: 0.9367\n",
      "Epoch 10/128\n",
      "1250/1250 [==============================] - 1662s - loss: 0.4544 - acc: 0.8539 - val_loss: 0.2302 - val_acc: 0.9328\n",
      "Epoch 11/128\n",
      "1249/1250 [============================>.] - ETA: 1s - loss: 0.4845 - acc: 0.8436\n",
      "Epoch 00010: reducing learning rate to 0.00010000000474974513.\n",
      "1250/1250 [==============================] - 1667s - loss: 0.4845 - acc: 0.8436 - val_loss: 0.2305 - val_acc: 0.9318\n",
      "Epoch 12/128\n",
      "1250/1250 [==============================] - 1664s - loss: 0.4966 - acc: 0.8393 - val_loss: 0.2363 - val_acc: 0.9303\n",
      "Epoch 13/128\n",
      "1250/1250 [==============================] - 1667s - loss: 0.4860 - acc: 0.8432 - val_loss: 0.2275 - val_acc: 0.9329\n",
      "Epoch 00012: early stopping\n",
      "CPU times: user 6h 6min 31s, sys: 5min 11s, total: 6h 11min 43s\n",
      "Wall time: 6h 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Current model has been trained on 68 epochs before early stopping.\n",
    "epochs     = 128\n",
    "batch_size = 100\n",
    "histories.append(model.fit_generator(\n",
    "    ext.input_output_generator(train, batch_size, order),\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=ext.input_output_generator(test, batch_size, order),\n",
    "    validation_steps=len(test) // batch_size,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=modelpath,\n",
    "            save_best_only=True,\n",
    "            verbose=0,),\n",
    "        keras.callbacks.EarlyStopping(patience=5, verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display information about the model after fitting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test.sort(key=lambda x: x.iloc[0][\"event_id\"])\n",
    "guesses          = model.predict(ext.extract_input(test, order))\n",
    "hits_correct     = metrics.percent_of_hits_assigned_correctly(test, guesses=guesses, order=order)\n",
    "tracks_correct   = metrics.percent_of_tracks_assigned_correctly(test, guesses=guesses, order=order, percent=1.0)\n",
    "n_tracks_correct = metrics.percent_of_events_with_correct_number_of_tracks(test, guesses=guesses, order=order)\n",
    "print(\"Percent of hits assigned correctly: {}%\".format(hits_correct * 100))\n",
    "print(\"Percent of tracks assigned correctly: {}%\".format(tracks_correct * 100))\n",
    "print(\"Percent of events with the correct number of tracks: {}%\".format(n_tracks_correct * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "print(\"Percent of hits assigned correctly: {}%\".format(\n",
    "    metrics.percent_of_hits_assigned_correctly(test[n], guesses[n], order) * 100))\n",
    "print(\"Percent of tracks assigned correctly: {}%\".format(\n",
    "    metrics.percent_of_tracks_assigned_correctly(test[n], guesses[n], order) * 100))\n",
    "_ = visuals.Plot2D(test[n], order, guesses[n]).plot(mode=\"zr\")\n",
    "_ = visuals.Plot2D(test[n], order).plot(mode=\"xy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_tracks, accuracy = metrics.accuracy_vs_tracks(test, guesses, order)\n",
    "r = range(n_tracks.min(), n_tracks.max() + 1)\n",
    "boxes = [[] for _ in r]\n",
    "for i in range(len(n_tracks)):\n",
    "    boxes[n_tracks[i] - n_tracks.min()].append(accuracy[i])\n",
    "visuals.boxplot(boxes, \"Number of Tracks VS. Discrete Accuracy\", \"Number of Tracks\", \"Discrete Accuracy\", xticks=list(r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
