{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "### Imports ####################################################################\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU\n",
    "from typing import Tuple, Callable, List, Optional\n",
    "from tracker import visuals, extractor, utils, metrics\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "Tensor = theano.tensor.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     1,
     14,
     26
    ]
   },
   "outputs": [],
   "source": [
    "### File Writers ###############################################################\n",
    "def write4d(file, array: np.ndarray) -> None:\n",
    "    for cube in array:\n",
    "        for matrix in cube:\n",
    "            for row in matrix:\n",
    "                for number in row:\n",
    "                    string = \"{0: >6.2f} | \".format(number)\n",
    "                    string = string.replace(\"-0.00\", \"     \")\n",
    "                    string = string.replace( \"0.00\",  \"    \")\n",
    "                    file.write(string)\n",
    "                file.write(\"\\n\")\n",
    "            file.write((\"-\" * 110) + \"\\n\")\n",
    "        file.write((\"=\" * 110) + \"\\n\" + (\"=\" * 110) + \"\\n\")\n",
    "\n",
    "def write3d(file, array: np.ndarray) -> None:\n",
    "    for matrix in array:\n",
    "        for row in matrix:\n",
    "            for number in row:\n",
    "                string = \"{0: >6.2f} | \".format(number)\n",
    "                string = string.replace(\"-0.00\", \"     \")\n",
    "                string = string.replace( \"0.00\",  \"    \")\n",
    "                file.write(string)\n",
    "            file.write(\"\\n\")\n",
    "            file.write((\"-\" * 110) + \"\\n\")\n",
    "        file.write((\"=\" * 110) + \"\\n\" + (\"=\" * 110) + \"\\n\")\n",
    "\n",
    "def write(filename: str, array: np.ndarray) -> None:\n",
    "    with open(filename, \"w\") as file:\n",
    "        if len(array.shape) == 4:\n",
    "            write4d(file, array)\n",
    "        elif len(array.shape) == 3:\n",
    "            write3d(file, array)\n",
    "        else:\n",
    "            file.write(str(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "(50, 3)\n",
      "(50, 12)\n"
     ]
    }
   ],
   "source": [
    "### Load in Data ###############################################################\n",
    "order  = [\"phi\", \"r\", \"z\"]\n",
    "frame  = pd.read_csv(\"data/sets/ACTS-SMALL-PREPARED.gz\")\n",
    "data   = extractor.extract_input(frame, order)\n",
    "matrix = extractor.extract_output(frame, order)\n",
    "input_shape  = data.shape[1:]\n",
    "output_shape = matrix.shape[1:]\n",
    "print(len(data))\n",
    "print(input_shape)\n",
    "print(output_shape)\n",
    "n = 3\n",
    "#visuals.display_matrices(data[1], matrix[n], order=order, noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     28,
     42,
     73,
     111,
     122
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.97  0.16 -5.02 -5.21 -8.48]\n"
     ]
    }
   ],
   "source": [
    "#### LossFunctionCreator #######################################################\n",
    "class LossFunctionCreator:\n",
    "    def __init__(self,\n",
    "            input_tensor : Tensor,\n",
    "            input_shape  : Tuple,\n",
    "            output_shape : Tuple,\n",
    "            order        : List[str],\n",
    "            ) -> None:\n",
    "        \"\"\" Initialize the instance variables. \"\"\"\n",
    "        self.__name__     = \"LossFunctionCreator\"\n",
    "        self.input_tensor = input_tensor\n",
    "        self.meshgrid     = self.make_meshgrid(output_shape)\n",
    "        self.input_shape  = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.order        = order\n",
    "\n",
    "    def make_meshgrid(self,\n",
    "            shape : Tuple[int, int],\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Create a meshgrid.\n",
    "        Example for shape (3, 5):\n",
    "            [[0, 1, 2, 3, 4],\n",
    "             [0, 1, 2, 3, 4],\n",
    "             [0, 1, 2, 3, 4]]\n",
    "        \"\"\"\n",
    "        return (T.mgrid[0:shape[0], 0:shape[1]][1])\n",
    "    \n",
    "    def combine_with_input_tensor(self,\n",
    "            input_tensor  : Tensor,\n",
    "            output_tensor : Tensor,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return the cartesian product of the input_tensor and the\n",
    "        output_tensor along the last two axes.\n",
    "        \"\"\"\n",
    "        input_list   = [input_tensor  for _ in range(self.output_shape[-1])]\n",
    "        output_list  = [output_tensor for _ in range(self.input_shape[-1])]\n",
    "        input_stack  = T.stack(input_list,  axis=-1)\n",
    "        output_stack = T.stack(output_list, axis=-2)\n",
    "        return input_stack * output_stack\n",
    "    \n",
    "    def combo_loss(self,\n",
    "            y_true : Tensor,\n",
    "            y_pred : Tensor,\n",
    "            ) -> Tensor:\n",
    "        \"\"\" A loss function. Temporary. \"\"\"\n",
    "        input_tensor = self.to_std_dist(self.input_tensor, axis=1)\n",
    "        true_combo   = self.combine_with_input_tensor(input_tensor, y_true)\n",
    "        pred_combo   = self.combine_with_input_tensor(input_tensor, y_pred)\n",
    "        diff_squared = (pred_combo - true_combo)**2\n",
    "        return diff_squared\n",
    "    \n",
    "    def regression_loss(self,\n",
    "            y_true : Tensor,\n",
    "            y_pred : Tensor,\n",
    "            ) -> Tensor:\n",
    "        input_tensor = self.input_tensor\n",
    "        # input_tensor = self.to_std_dist(self.input_tensor, axis=1)\n",
    "        tensor = None\n",
    "        for i in range(output_shape[1]):  # For each track...\n",
    "            pred_mask = self.get_track_mask(y_pred, i)\n",
    "            true_mask = self.get_track_mask(y_true, i)\n",
    "            \n",
    "            pred_num_hits = pred_mask.sum(-1).sum(-1) + 2  # Avoid Div(0).\n",
    "            true_num_hits = true_mask.sum(-1).sum(-1) + 2  # Avoid Div(0).\n",
    "            \n",
    "            pred_masked = pred_mask * input_tensor\n",
    "            true_masked = true_mask * input_tensor\n",
    "            \n",
    "            pred_line = self.linear_regression(pred_masked, pred_num_hits)\n",
    "            true_line = self.linear_regression(true_masked, true_num_hits)\n",
    "            \n",
    "            diff   = (pred_line - true_line)**2\n",
    "            tensor = diff if tensor is None else tensor + diff\n",
    "        return (tensor / self.output_shape[1])\n",
    "    \n",
    "    def to_std_dist(self,\n",
    "            tensor : Tensor,\n",
    "            axis   : int,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Transform the tensor's values to be the number of standard deviations\n",
    "        that the value is from the mean along the specified axis.\n",
    "        \"\"\"\n",
    "        mean = tensor.mean(axis=axis, keepdims=True)\n",
    "        std  = tensor.std(axis=axis, keepdims=True)\n",
    "        return (tensor - mean) / std\n",
    "    \n",
    "    def softmax(self,\n",
    "            tensor     : Tensor,\n",
    "            axis       : Optional[int] = None,\n",
    "            refinement : float = 1,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return the softmax of the tensor along the specified axis.\n",
    "        Higher refinement yields sharper, more accurate results, but also\n",
    "        tends to yield NaNs for large tensor values.\n",
    "        \"\"\"\n",
    "        exponent = (refinement * tensor).exp()\n",
    "        return exponent / exponent.sum(axis=axis, keepdims=True)\n",
    "\n",
    "    def softargmax(self,\n",
    "            tensor     : Tensor,\n",
    "            indices    : Tensor,\n",
    "            axis       : Optional[int] = None,\n",
    "            refinement : float = 1,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return the argsoftmax of the tensor along the specified axis.\n",
    "        Higher refinement yields sharper, more accurate results, but also\n",
    "        tends to yield NaNs for large tensor values.\n",
    "        \"\"\"\n",
    "        return (self.softmax(tensor, axis, refinement) * indices).sum(axis=axis)\n",
    "    \n",
    "    def get_order_mask(self,\n",
    "            string : str,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return a mask such that when output is multiplied by this mask,\n",
    "        only the column corresponding to the *string* category remains.\n",
    "        \"\"\"\n",
    "        mask = np.zeros(len(self.order))\n",
    "        mask[self.order.index(string)] = 1\n",
    "        return T.as_tensor_variable(mask)\n",
    "    \n",
    "    def get_track_mask(self,\n",
    "            output   : Tensor,\n",
    "            track_id : int,\n",
    "            aref     : int = 512,  # Refinement value for softargmax.\n",
    "            mref     : int =   5,  # Refinement value for mask values.\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Retrieve a tensor containing a mask such that if self.tensor_input\n",
    "        was multiplied by the mask, the result would be a tensor containing\n",
    "        the positions of all hits with the specified track_id.\n",
    "        \"\"\"\n",
    "        cats = self.softargmax(output, self.meshgrid, refinement=aref, axis=-1)\n",
    "        fill = T.fill(cats, track_id)\n",
    "        diff = (cats - fill)**2\n",
    "        mask = 1 / (mref * diff).exp()\n",
    "        mask = mask.reshape((*T.shape(mask), 1))\n",
    "        return mask\n",
    "    \n",
    "    def linear_regression(self,\n",
    "            tensor : Tensor,\n",
    "            length : Tensor,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given a tensor, and the number of hits within the tensor,\n",
    "        return the two parameters (m, b) of the least squares\n",
    "        regression line with equation f[x] = (m * x) + b.\n",
    "        \"\"\"\n",
    "        e = 2 * K.common.epsilon()  # Epsilon to avoid division by 0.\n",
    "        p = (tensor * self.get_order_mask(\"phi\")).sum(-1)\n",
    "        r = (tensor * self.get_order_mask(\"r\")).sum(-1)  # r values.\n",
    "        z = (tensor * self.get_order_mask(\"z\")).sum(-1)  # z values.\n",
    "        \n",
    "        d = (length * (r**2).sum(-1)) - r.sum(-1)**2 + e  # Denominator.\n",
    "        m = (length * (r * z).sum(-1) - r.sum(-1) * z.sum(-1)) / d\n",
    "        b = (z.sum(-1) * (r**2).sum(-1) - r.sum(-1) * (r * z).sum(-1)) / d\n",
    "        return m #T.stack([m, b]).T\n",
    "    \n",
    "    def __call__(self,\n",
    "            y_true : Tensor,\n",
    "            y_pred : Tensor,\n",
    "            ) -> Tensor:\n",
    "        \"\"\" Return a Tensor that measures the loss of a model. \"\"\"\n",
    "        return self.regression_loss(y_true, y_pred)\n",
    "    \n",
    "A = T.tensor3(\"A\")\n",
    "B = T.tensor3(\"B\")\n",
    "C = T.tensor3(\"C\")\n",
    "D = LossFunctionCreator(A, input_shape, output_shape, order)\n",
    "E = D(B, C)\n",
    "F = theano.function([A, B, C], E, on_unused_input='ignore')\n",
    "#print(theano.printing.debugprint(E))\n",
    "positions   = data  [0:5]\n",
    "true_matrix = matrix[0:5]\n",
    "pred_matrix = np.random.rand(*true_matrix.shape)\n",
    "pred_matrix = pred_matrix / pred_matrix.sum(-1, keepdims=True)\n",
    "evaluation = F(positions, true_matrix, pred_matrix).round(2)\n",
    "print(evaluation)\n",
    "write(\"output4.txt\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Define Model ###############################################################\n",
    "# Input Layer:\n",
    "input_layer = Input(\n",
    "    name  = \"Input\", \n",
    "    shape = input_shape,\n",
    ")\n",
    "\n",
    "# Hidden Layers:\n",
    "# model_layer = Dense(\n",
    "#     name = \"Dense\",\n",
    "#     activation = \"relu\",\n",
    "#     units = 512,\n",
    "#     kernel_initializer = \"uniform\",\n",
    "# )(input_layer)\n",
    "model_layer = GRU(\n",
    "    name = \"GRU 1\",\n",
    "    return_sequences = True,\n",
    "    units = 256,\n",
    ")(input_layer)\n",
    "model_layer = GRU(\n",
    "    name = \"GRU 2\",\n",
    "    return_sequences = True,\n",
    "    units = 256,\n",
    ")(model_layer)\n",
    "model_layer = GRU(\n",
    "    name = \"GRU 3\",\n",
    "    return_sequences = True,\n",
    "    units = 256,\n",
    ")(model_layer)\n",
    "\n",
    "# Output Layer:\n",
    "output_layer = Dense(\n",
    "    name  = \"Softmax\",\n",
    "    units = output_shape[1],\n",
    "    activation = \"softmax\",\n",
    "    kernel_initializer = \"uniform\",\n",
    ")(model_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "loss  = LossFunctionCreator(input_layer, input_shape, output_shape, order)\n",
    "opt   = keras.optimizers.RMSprop(lr=0.000001)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Fit Model ##################################################################\n",
    "histories = model.fit(\n",
    "    data, \n",
    "    matrix, \n",
    "    epochs=150, \n",
    "    batch_size=1,\n",
    "    verbose=2, \n",
    "    validation_data=(data, matrix)\n",
    ")\n",
    "predictions = model.predict(data[0:2])\n",
    "write(\"output.txt\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Graph Loss ################################################################\n",
    "plt.plot(histories.history['loss'])\n",
    "plt.plot(histories.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Graph Accuracy ############################################################\n",
    "plt.plot(histories.history['acc'])\n",
    "plt.plot(histories.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
