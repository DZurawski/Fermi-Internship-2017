{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:0C:00.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "%matplotlib notebook\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import sys\n",
    "from keras.layers import TimeDistributed, Dense, Dropout, GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from tracker import extractor as ext, utils, metrics, visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is list of 25000 events (200320 bytes).\n",
      "Test is list of 3600 events (30120 bytes).\n",
      "CPU times: user 10.5 s, sys: 312 ms, total: 10.8 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainpath   = \"data/sets/UNIF-10N-25T-25000E-235R.gz\"\n",
    "testpath    = \"data/sets/RAMP-10N-25T-3600E-235R.gz\"\n",
    "train_frame = pd.read_csv(trainpath)\n",
    "test_frame  = pd.read_csv(testpath)\n",
    "train       = utils.list_of_groups(train_frame, group=\"event_id\")\n",
    "test        = utils.list_of_groups(test_frame,  group=\"event_id\")\n",
    "print(\"Train is list of {0} events ({1} bytes).\".format(len(train), sys.getsizeof(train)))\n",
    "print(\"Test is list of {0} events ({1} bytes).\".format(len(test), sys.getsizeof(test)))\n",
    "if (not utils.is_prepared(train_frame)) or (not utils.is_prepared(test_frame)):\n",
    "    print(\"Warning: frame is not prepared.\")\n",
    "    print(\"Look at the prepare_frame() function in tracker/extractor.py\")\n",
    "else:\n",
    "    del train_frame\n",
    "    del test_frame # To save on memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[:100]\n",
    "test  = test[:100]\n",
    "order = [\"phi\", \"r\", \"z\"]\n",
    "input_shape  = (235, 3)\n",
    "n_categories = 25 + 2\n",
    "optimizer    = keras.optimizers.RMSprop(lr=0.001)\n",
    "histories    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This message\n",
      "This message is now complete.\n"
     ]
    }
   ],
   "source": [
    "def arbitrary_function(string):\n",
    "    arbitrary_function.message += string\n",
    "    return 0\n",
    "\n",
    "arbitrary_function.message = \"\"\n",
    "arbitrary_function(\"This message\")\n",
    "print(arbitrary_function.message)\n",
    "arbitrary_function(\" is now complete.\")\n",
    "print(arbitrary_function.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "class Loss:\n",
    "    def __init__(self):\n",
    "        self.number_of_times_called = 0\n",
    "        \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        self.number_of_times_called += 1\n",
    "        return K.sum(K.log(y_true) - K.log(y_pred))\n",
    "\n",
    "custom_loss = Loss()\n",
    "custom_loss.__name__ = \"custom_loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model = Sequential()\n",
    "model.add(Dropout(rate=1/32, input_shape=input_shape))\n",
    "model.add(TimeDistributed(Dense(units=n_categories, kernel_initializer=\"uniform\", activation=\"softmax\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_17 (Dropout)         (None, 235, 3)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 235, 27)           108       \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=custom_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 1s - loss: nan - acc: 0.0320 - val_loss: nan - val_acc: 0.0361\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 1s - loss: nan - acc: 0.0352 - val_loss: nan - val_acc: 0.0360\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 1s - loss: nan - acc: 0.0352 - val_loss: nan - val_acc: 0.0360\n",
      "CPU times: user 4.34 s, sys: 300 ms, total: 4.64 s\n",
      "Wall time: 4.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs     = 3\n",
    "batch_size = 10\n",
    "histories.append(model.fit_generator(\n",
    "    ext.input_output_generator(train, batch_size, order),\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=ext.input_output_generator(test, batch_size, order),\n",
    "    validation_steps=len(test) // batch_size,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, verbose=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(custom_loss.number_of_times_called)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
