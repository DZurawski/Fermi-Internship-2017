{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "from IPython.display import display\n",
    "from typing import Iterable, List, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def flatten(\n",
    "        iterable: Iterable\n",
    "        ) -> Iterable:\n",
    "    \"\"\" Return a flattened iterable from a nested iterable.\n",
    "        [[3, [4, 5]], 6, [[[7]]]] -> [3, 4, 5, 6, 7]\n",
    "    \"\"\"\n",
    "    for item in iterable:\n",
    "        if  isinstance(item, Iterable) and not isinstance(item, (str, bytes)):\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item\n",
    "\n",
    "\n",
    "def parse_file(\n",
    "        filename         : str,\n",
    "        initial_event_id : int      = 0,\n",
    "        ignored_columns  : Sequence = (),\n",
    "        ) -> Iterable[Iterable]:\n",
    "    \"\"\" Parses the lines in the file from 'filename' to a format\n",
    "        appropriate for passing into a pandas DataFrame constructor.\n",
    "    \"\"\"\n",
    "    event_id = initial_event_id\n",
    "    with open(filename) as file:\n",
    "        lines = filter(None, (line.strip() for line in file))\n",
    "        for line in lines:\n",
    "            if line.startswith(\"#\"):\n",
    "                event_id += 1\n",
    "            else:\n",
    "                j_list = json.loads(\"[{0}]\".format(line))\n",
    "                for column in ignored_columns:\n",
    "                    del j_list[column]\n",
    "                j_list.append(event_id)\n",
    "                yield flatten(j_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "clusters_columns = [\n",
    "    \"hit_nr\", \"barcode\", \"volume_id\", \"layer_id\",\n",
    "    \"lx\",     \"ly\",      \"elx\",       \"ely\",    \n",
    "    \"gx\",     \"gy\",      \"gz\",        \"phi\",    \n",
    "    \"theta\",  \"ephi\",    \"etheta\",    \"event_id\",\n",
    "]\n",
    "particles_columns = [\n",
    "    \"barcode\",  \"vertex_x\", \"vertex_y\",\n",
    "    \"vertex_z\", \"momentum\", \"theta\",\n",
    "    \"phi\",      \"charge\",   \"event_id\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction from a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "number = 1\n",
    "base_directory     = \"/inputdata/ACTS/prod_mu10_pt1000_2017_07_29\"\n",
    "clusters_filename  = base_directory + \"/clusters_{0}.csv\".format(number)\n",
    "particles_filename = base_directory + \"/particles_{0}.csv\".format(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "clusters_lines = parse_file(clusters_filename, ignored_columns=[7])\n",
    "clusters_frame = pd.DataFrame(clusters_lines, columns=clusters_columns)\n",
    "clusters_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "particles_lines = parse_file(particles_filename)\n",
    "particles_frame = pd.DataFrame(particles_lines, columns=particles_columns)\n",
    "particles_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "left_frame     = clusters_frame\n",
    "right_frame    = particles_frame[[\"event_id\", \"barcode\", \"momentum\", \"charge\"]]\n",
    "combined_frame = left_frame.merge(right_frame, on=[\"event_id\", \"barcode\"])\n",
    "combined_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "gx    = combined_frame[\"gx\"]\n",
    "gy    = combined_frame[\"gy\"]\n",
    "gz    = combined_frame[\"gz\"]\n",
    "phi   = np.arctan2(gy, gx)\n",
    "r     = np.sqrt(gx**2 + gy**2)\n",
    "frame = combined_frame.assign(phi=phi, r=r, z=gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Eliminate duplicate hits that were caused by imperfections in the detector.\n",
    "frame = frame.sort_values(\"r\")\n",
    "frame = frame.drop_duplicates([\"event_id\", \"barcode\", \"layer_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Specify the volume to use. Each volume is a different detector configuration.\n",
    "frame = frame[frame[\"volume_id\"] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Set radiuses to be the same for each layer.\n",
    "for layer_id in frame[\"layer_id\"].unique():\n",
    "    ind = frame[\"layer_id\"] == layer_id\n",
    "    rs  = frame[ind][\"r\"]\n",
    "    med = rs.median()\n",
    "    frame.loc[ind, \"r\"] = med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Put limits on the number of tracks per event. \n",
    "max_tracks = 50\n",
    "min_tracks = 2\n",
    "frames = [f for (_, f) in frame.groupby(\"event_id\", sort=False)]\n",
    "for i, f in enumerate(frames):\n",
    "    barcodes = f[\"barcode\"].unique()\n",
    "    if len(barcodes) < min_tracks:\n",
    "        frames[i] = pd.DataFrame()\n",
    "    if len(barcodes) > max_tracks:\n",
    "        length = np.random.randint(min_tracks, max_tracks + 1)\n",
    "        barcodes = np.random.choice(barcodes, length, replace=False)\n",
    "        f = f[f[\"barcode\"].isin(barcodes)]\n",
    "        frames[i] = f\n",
    "frame = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Clean up the frame a bit.\n",
    "frame = frame[[\"event_id\", \"barcode\", \"phi\", \"r\", \"z\", \"momentum\", \"charge\"]]\n",
    "frame = frame.sort_values([\"event_id\", \"barcode\", \"r\"])\n",
    "frame.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction from multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def extract(\n",
    "        clusters_filename  : str, \n",
    "        particles_filename : str,\n",
    "        initial_event_id   : int = 0,\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\" Everything in one function.\n",
    "        Depending on the size of the file, this function could take a long\n",
    "        time. Most of the time is spent parsing the csv files within the\n",
    "        first 4 lines.\n",
    "    \"\"\"\n",
    "    clusters_lines = parse_file(\n",
    "        clusters_filename,\n",
    "        ignored_columns=[7],\n",
    "        initial_event_id=initial_event_id)\n",
    "    clusters_frame = pd.DataFrame(clusters_lines, columns=clusters_columns)\n",
    "    \n",
    "    particles_lines = parse_file(\n",
    "        particles_filename, \n",
    "        initial_event_id=initial_event_id)\n",
    "    particles_frame = pd.DataFrame(particles_lines, columns=particles_columns)\n",
    "    \n",
    "    left  = clusters_frame\n",
    "    right = particles_frame[[\"event_id\", \"barcode\", \"momentum\", \"charge\"]]\n",
    "    combined_frame = left.merge(right, on=[\"event_id\", \"barcode\"])\n",
    "    \n",
    "    gx    = combined_frame[\"gx\"]\n",
    "    gy    = combined_frame[\"gy\"]\n",
    "    gz    = combined_frame[\"gz\"]\n",
    "    phi   = np.arctan2(gy, gx)\n",
    "    r     = np.sqrt(gx**2 + gy**2)\n",
    "    frame = combined_frame.assign(phi=phi, r=r, z=gz)\n",
    "    \n",
    "    frame = frame.sort_values(\"r\")\n",
    "    frame = frame.drop_duplicates([\"event_id\", \"barcode\", \"layer_id\"])\n",
    "    \n",
    "    frame = frame[frame[\"volume_id\"] == 8]\n",
    "    \n",
    "    for layer_id in frame[\"layer_id\"].unique():\n",
    "        ind = frame[\"layer_id\"] == layer_id\n",
    "        rs  = frame[ind][\"r\"]\n",
    "        med = rs.median()\n",
    "        frame.loc[ind, \"r\"] = med\n",
    "    \n",
    "    cols = [\"event_id\", \"barcode\", \"phi\", \"r\", \"z\", \"momentum\", \"charge\"]\n",
    "    frame = frame[cols]\n",
    "    frame = frame.sort_values([\"event_id\", \"barcode\", \"r\"])\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from file 1. Initial Event ID is 0\n",
      "Extracting from file 2. Initial Event ID is 101\n",
      "Extracting from file 3. Initial Event ID is 202\n",
      "Extracting from file 4. Initial Event ID is 303\n",
      "Extracting from file 5. Initial Event ID is 404\n",
      "Extracting from file 6. Initial Event ID is 505\n",
      "Extracting from file 7. Initial Event ID is 606\n",
      "Extracting from file 8. Initial Event ID is 707\n",
      "Extracting from file 9. Initial Event ID is 808\n",
      "Extracting from file 10. Initial Event ID is 909\n",
      "Extracting from file 11. Initial Event ID is 1010\n",
      "Extracting from file 12. Initial Event ID is 1111\n",
      "Extracting from file 13. Initial Event ID is 1212\n",
      "Extracting from file 14. Initial Event ID is 1313\n",
      "Extracting from file 15. Initial Event ID is 1414\n",
      "Extracting from file 16. Initial Event ID is 1515\n",
      "Extracting from file 17. Initial Event ID is 1616\n",
      "Extracting from file 18. Initial Event ID is 1717\n",
      "Extracting from file 19. Initial Event ID is 1818\n",
      "Extracting from file 20. Initial Event ID is 1919\n",
      "Extracting from file 21. Initial Event ID is 2020\n",
      "Extracting from file 22. Initial Event ID is 2121\n",
      "Extracting from file 23. Initial Event ID is 2222\n",
      "Extracting from file 24. Initial Event ID is 2323\n",
      "Extracting from file 25. Initial Event ID is 2424\n",
      "Extracting from file 26. Initial Event ID is 2525\n",
      "Extracting from file 27. Initial Event ID is 2626\n",
      "Extracting from file 28. Initial Event ID is 2727\n",
      "Extracting from file 29. Initial Event ID is 2828\n",
      "Extracting from file 30. Initial Event ID is 2929\n",
      "Extracting from file 31. Initial Event ID is 3030\n",
      "Extracting from file 32. Initial Event ID is 3131\n",
      "Extracting from file 33. Initial Event ID is 3232\n",
      "Extracting from file 34. Initial Event ID is 3333\n",
      "Extracting from file 35. Initial Event ID is 3434\n",
      "Extracting from file 36. Initial Event ID is 3535\n",
      "Extracting from file 37. Initial Event ID is 3636\n",
      "Extracting from file 38. Initial Event ID is 3737\n",
      "Extracting from file 39. Initial Event ID is 3838\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4ba6f1e26c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'################################################################################\\nframes = []\\ninitial_event_id = 0\\nbase_directory = \"/inputdata/ACTS/prod_mu200_pt500_2017_07_26\"\\nfor i in range(1, 1 + 100):\\n    print(\"Extracting from file {0}. Initial Event ID is {1}\".format(i, initial_event_id))\\n    try:\\n        clusters_filename  = base_directory + \"/clusters_{0}.csv\".format(i)\\n        particles_filename = base_directory + \"/particles_{0}.csv\".format(i)\\n        frame = extract(\\n            clusters_filename=clusters_filename, \\n            particles_filename=particles_filename,\\n            initial_event_id=initial_event_id,)\\n        initial_event_id = frame[\"event_id\"].max() + 1\\n        frames.append(frame)\\n    except FileNotFoundError as error:\\n        print(error)\\nframe = pd.concat(frames)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-29671fa99527>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(clusters_filename, particles_filename, initial_event_id)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mignored_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         initial_event_id=initial_event_id)\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mclusters_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclusters_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     particles_lines = parse_file(\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   5635\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5636\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5637\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5638\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m   5639\u001b[0m                                dtype=dtype)\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mlmap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-19f07e0a7c8b>\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m  \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/typing.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# we just skip the cache check -- instance checks for generic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;31m# classes are supposed to be rare anyways.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/typing.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0;31m# If we break out of the loop, the superclass gets a chance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__extra__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenericMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Check cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Check negative cache; may have to invalidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################################################################\n",
    "frames = []\n",
    "initial_event_id = 0\n",
    "base_directory = \"/inputdata/ACTS/prod_mu200_pt500_2017_07_26\"\n",
    "for i in range(1, 1 + 100):\n",
    "    print(\"Extracting from file {0}. Initial Event ID is {1}\".format(i, initial_event_id))\n",
    "    try:\n",
    "        clusters_filename  = base_directory + \"/clusters_{0}.csv\".format(i)\n",
    "        particles_filename = base_directory + \"/particles_{0}.csv\".format(i)\n",
    "        frame = extract(\n",
    "            clusters_filename=clusters_filename, \n",
    "            particles_filename=particles_filename,\n",
    "            initial_event_id=initial_event_id,)\n",
    "        initial_event_id = frame[\"event_id\"].max() + 1\n",
    "        frames.append(frame)\n",
    "    except FileNotFoundError as error:\n",
    "        print(error)\n",
    "frame = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hits: 30341559\n",
      "Number of Events: 3800\n",
      "Min Number of Tracks: 1630\n",
      "Max Number of Tracks: 3553\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Hits: {}\".format(len(frame)))\n",
    "print(\"Number of Events: {}\".format(len(frame[\"event_id\"].unique())))\n",
    "tracks  = [value for (_, value) in frame.groupby([\"event_id\"])]\n",
    "lengths = [len(value[\"barcode\"].unique()) for value in tracks]\n",
    "print(\"Min Number of Tracks: {}\".format(min(lengths)))\n",
    "print(\"Max Number of Tracks: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719643198 bytes\n"
     ]
    }
   ],
   "source": [
    "filepath = \"data/sets/ACTS-MU200-EV3800.gz\"\n",
    "frame.to_csv(filepath, compression=\"gzip\")\n",
    "print(\"{0} bytes\".format(os.path.getsize(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
