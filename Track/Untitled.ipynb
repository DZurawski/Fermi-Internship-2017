{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 28 20:02:03 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 0000:04:00.0     Off |                  N/A |\n",
      "| 27%   33C    P8     9W / 180W |    434MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 1080    Off  | 0000:05:00.0     Off |                  N/A |\n",
      "| 27%   35C    P8     9W / 180W |      2MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 1080    Off  | 0000:06:00.0     Off |                  N/A |\n",
      "| 27%   33C    P8     9W / 180W |    557MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 1080    Off  | 0000:07:00.0     Off |                  N/A |\n",
      "| 27%   32C    P8     9W / 180W |   1858MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 1080    Off  | 0000:0B:00.0     Off |                  N/A |\n",
      "| 27%   33C    P8    10W / 180W |   1399MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 1080    Off  | 0000:0C:00.0     Off |                  N/A |\n",
      "| 27%   36C    P8    10W / 180W |   7822MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 1080    Off  | 0000:0D:00.0     Off |                  N/A |\n",
      "| 27%   35C    P8     9W / 180W |   1399MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 1080    Off  | 0000:0E:00.0     Off |                  N/A |\n",
      "| 27%   34C    P8    10W / 180W |   1708MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID  Type  Process name                               Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:06:00.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "%matplotlib notebook\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import TimeDistributed, Dense, Dropout, GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from tracker import extractor as ext, utils, metrics, visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is list of 4800 events.\n",
      "Test is list of 3600 events.\n",
      "CPU times: user 2.96 s, sys: 60 ms, total: 3.02 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelpath   = \"data/models/UNIF-10N-25T-200E-235R-RZ.h5\"\n",
    "trainpath   = \"data/sets/UNIF-10N-25T-200E-235R.gz\"\n",
    "testpath    = \"data/sets/RAMP-10N-25T-235R.gz\"\n",
    "train_frame = pd.read_csv(trainpath)\n",
    "test_frame  = pd.read_csv(testpath)\n",
    "train = utils.list_of_groups(train_frame, group=\"event_id\")\n",
    "test  = utils.list_of_groups(test_frame,  group=\"event_id\")\n",
    "print(\"Train is list of {} events.\".format(len(train)))\n",
    "print(\"Test is list of {} events.\".format(len(test)))\n",
    "if (not utils.is_prepared(train_frame)) or (not utils.is_prepared(test_frame)):\n",
    "    print(\"Warning: frame is not prepared.\")\n",
    "    print(\"Look at the prepare_frame() function in tracker/extractor.py\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\"phi\", \"r\", \"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape  = (235, 2)\n",
    "n_categories = 25 + 2\n",
    "optimizer    = keras.optimizers.RMSprop(lr=0.001)\n",
    "histories    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 235, 256)          397824    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 235, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 235, 256)          787968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 235, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 235, 256)          787968    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 235, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 235, 27)           6939      \n",
      "=================================================================\n",
      "Total params: 1,980,699\n",
      "Trainable params: 1,980,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(\n",
    "    GRU(units=256, return_sequences=True, recurrent_dropout=1/2, implementation=2),\n",
    "    merge_mode=\"mul\",\n",
    "    input_shape=input_shape))\n",
    "model.add(Dropout(rate=1/2))\n",
    "model.add(Bidirectional(\n",
    "    GRU(units=256, return_sequences=True, recurrent_dropout=1/2, implementation=2),\n",
    "    merge_mode=\"mul\"))\n",
    "model.add(Dropout(rate=1/2))\n",
    "model.add(Bidirectional(\n",
    "    GRU(units=256, return_sequences=True, recurrent_dropout=1/2, implementation=2),\n",
    "    merge_mode=\"mul\"))\n",
    "model.add(Dropout(rate=1/2))\n",
    "model.add(TimeDistributed(Dense(units=n_categories, kernel_initializer=\"uniform\", activation=\"softmax\")))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800 samples, validate on 3600 samples\n",
      "Epoch 1/32\n",
      "4800/4800 [==============================] - 76s - loss: 0.8023 - acc: 0.6997 - val_loss: 0.4971 - val_acc: 0.8003\n",
      "Epoch 2/32\n",
      "4800/4800 [==============================] - 76s - loss: 0.7813 - acc: 0.7076 - val_loss: 0.5096 - val_acc: 0.7982\n",
      "Epoch 3/32\n",
      "4800/4800 [==============================] - 76s - loss: 0.7642 - acc: 0.7140 - val_loss: 0.5194 - val_acc: 0.7914\n",
      "Epoch 4/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.7498 - acc: 0.7205 - val_loss: 0.4400 - val_acc: 0.8343\n",
      "Epoch 5/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.7340 - acc: 0.7243 - val_loss: 0.5268 - val_acc: 0.7899\n",
      "Epoch 6/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.7223 - acc: 0.7306 - val_loss: 0.4366 - val_acc: 0.8338\n",
      "Epoch 7/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.7096 - acc: 0.7328 - val_loss: 0.3986 - val_acc: 0.8615\n",
      "Epoch 8/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.7011 - acc: 0.7378 - val_loss: 0.4175 - val_acc: 0.8475\n",
      "Epoch 9/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6896 - acc: 0.7409 - val_loss: 0.4132 - val_acc: 0.8484\n",
      "Epoch 10/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6786 - acc: 0.7465 - val_loss: 0.4746 - val_acc: 0.8093\n",
      "Epoch 11/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6720 - acc: 0.7489 - val_loss: 0.3733 - val_acc: 0.8710\n",
      "Epoch 12/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6582 - acc: 0.7534 - val_loss: 0.3921 - val_acc: 0.8556\n",
      "Epoch 13/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6565 - acc: 0.7550 - val_loss: 0.3698 - val_acc: 0.8672\n",
      "Epoch 14/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6466 - acc: 0.7588 - val_loss: 0.3609 - val_acc: 0.8734\n",
      "Epoch 15/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6342 - acc: 0.7635 - val_loss: 0.3876 - val_acc: 0.8516\n",
      "Epoch 16/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6336 - acc: 0.7648 - val_loss: 0.3483 - val_acc: 0.8782\n",
      "Epoch 17/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6182 - acc: 0.7704 - val_loss: 0.3965 - val_acc: 0.8487\n",
      "Epoch 18/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6165 - acc: 0.7717 - val_loss: 0.3437 - val_acc: 0.8764\n",
      "Epoch 19/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6171 - acc: 0.7718 - val_loss: 0.3455 - val_acc: 0.8829\n",
      "Epoch 20/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6034 - acc: 0.7775 - val_loss: 0.3244 - val_acc: 0.8903\n",
      "Epoch 21/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.6026 - acc: 0.7772 - val_loss: 0.3320 - val_acc: 0.8818\n",
      "Epoch 22/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5957 - acc: 0.7810 - val_loss: 0.3226 - val_acc: 0.8914\n",
      "Epoch 23/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5927 - acc: 0.7828 - val_loss: 0.3219 - val_acc: 0.8896\n",
      "Epoch 24/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5836 - acc: 0.7859 - val_loss: 0.3106 - val_acc: 0.8970\n",
      "Epoch 25/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5840 - acc: 0.7861 - val_loss: 0.3070 - val_acc: 0.8977\n",
      "Epoch 26/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5744 - acc: 0.7891 - val_loss: 0.3436 - val_acc: 0.8811\n",
      "Epoch 27/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5709 - acc: 0.7918 - val_loss: 0.3106 - val_acc: 0.8980\n",
      "Epoch 28/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5711 - acc: 0.7912 - val_loss: 0.2958 - val_acc: 0.9019\n",
      "Epoch 29/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5644 - acc: 0.7942 - val_loss: 0.2996 - val_acc: 0.8992\n",
      "Epoch 30/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5619 - acc: 0.7960 - val_loss: 0.2910 - val_acc: 0.9051\n",
      "Epoch 31/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5550 - acc: 0.7989 - val_loss: 0.2949 - val_acc: 0.9021\n",
      "Epoch 32/32\n",
      "4800/4800 [==============================] - 77s - loss: 0.5519 - acc: 0.8002 - val_loss: 0.2933 - val_acc: 0.9023\n",
      "CPU times: user 40min 54s, sys: 19.5 s, total: 41min 13s\n",
      "Wall time: 41min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# L1 = np.array([ext.extract_input(a, order)[:, 1:] for a in train])\n",
    "# L2 = np.array([ext.extract_input(a, order)[:, 1:] for a in test])\n",
    "# T1 = np.array([ext.extract_output(a, order) for a in train])\n",
    "# T2 = np.array([ext.extract_output(a, order) for a in test])\n",
    "\n",
    "\n",
    "epochs     = 32\n",
    "batch_size = 100\n",
    "histories.append(model.fit(\n",
    "    L1, T1,\n",
    "    batch_size=64,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(L2, T2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
