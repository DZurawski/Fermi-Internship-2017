{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place to test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T15:52:51.111338Z",
     "start_time": "2017-07-03T15:52:46.921647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Author: Daniel Zurawski\n",
    "# Author: Keshav Kapoor\n",
    "# Organization: Fermilab\n",
    "# Grammar: Python 3.6.1\n",
    "\n",
    "%matplotlib notebook\n",
    "import keras # Neural network models\n",
    "import pandas as pd # Data frames\n",
    "import numpy as np  # numerical python\n",
    "from tracker3d import loader, utils, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T15:53:17.339823Z",
     "start_time": "2017-07-03T15:52:51.113335Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# How hit columns should be ordered.\n",
    "ORDERING = (\"r\", \"z\", \"phi\")\n",
    "\n",
    "# Name of file to save/load train and target data to/from.\n",
    "filename = \"nevall_tpeall_tsall_rzp.npz\"\n",
    "\n",
    "# True if you want to load. False if you want to create your own data.\n",
    "load_from_file = True\n",
    "\n",
    "# Retrieve the data and store it into *train* and *target*.\n",
    "if load_from_file:  # Much faster than creating your own!\n",
    "    train, target = loader.from_file(filename)\n",
    "else:\n",
    "    frame = pd.read_csv(\"datasets/standard_curves100MeV.csv\")\n",
    "    train, target = loader.from_frame(\n",
    "        frame,\n",
    "        nev=99999,\n",
    "        tpe=9999,\n",
    "        ts=9999,\n",
    "        variable_data=True,\n",
    "        verbose=True,\n",
    "        order=ORDERING)\n",
    "    loader.to_file(train, target, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T15:41:40.643265Z",
     "start_time": "2017-07-03T15:41:40.314054Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a taste for how an event looks by plotting a random one.\n",
    "event_number = np.random.randint(0, len(train))\n",
    "\n",
    "print(\"Event {}\".format(event_number))\n",
    "\n",
    "utils.plot3d(\n",
    "    train[event_number],\n",
    "    target[event_number],\n",
    "    target[event_number],\n",
    "    order=ORDERING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T19:11:23.150356Z",
     "start_time": "2017-06-29T19:11:22.990241Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the event's hits and category probability matrix.\n",
    "utils.display_side_by_side(\n",
    "    train[event_number],\n",
    "    target[event_number],\n",
    "    order=ORDERING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T14:24:33.782166Z",
     "start_time": "2017-07-03T14:24:33.777160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be used when we define our model.\n",
    "from keras.layers import TimeDistributed, Dense, LSTM\n",
    "from keras.layers import Dropout, GRU, Bidirectional\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T14:24:42.514389Z",
     "start_time": "2017-07-03T14:24:41.167701Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# It is time to define a model.\n",
    "trn_prcnt    = 0.25  # The percentage of events that are used for training.\n",
    "in_idx       = (len(train) - int(trn_prcnt * len(train)), len(train))   # Used for training. \n",
    "test_idx     = (0, len(train) - int(trn_prcnt * len(train)))  # For prediction.\n",
    "input_shape  = train[0].shape # Shape of an event.\n",
    "output_shape = target.shape[2] # Number of tracks per event\n",
    "epochs       = 128\n",
    "batch_size   = 90\n",
    "opt          = 'rmsprop'\n",
    "\n",
    "# Create the model.\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        GRU(\n",
    "            128,\n",
    "            return_sequences=True,\n",
    "            implementation=2,\n",
    "            stateful=True),\n",
    "        batch_input_shape=(batch_size, input_shape[0], input_shape[1])\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.3))\n",
    "model.add(TimeDistributed(Dense(output_shape, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# Print a summary of the model.\n",
    "print(\"Training on events {0} to {1}.\".format(in_idx[0], in_idx[1]))\n",
    "print(\"Epochs: {0}, Batch Size: {1}, Validation Split: {2}%\".format(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    valsplit * 100))\n",
    "print(\"Total events: {0} ({1}%).\".format(\n",
    "    int((in_idx[1] - in_idx[0]) * (1 - valsplit)), \n",
    "    trn_prcnt * 100 * (1 - valsplit))) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T14:26:40.475290Z",
     "start_time": "2017-07-03T14:24:48.540238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# It is time to train the model.\n",
    "np.random.seed(7) # For reproducibility\n",
    "test_train  = train[test_idx[0]:test_idx[1]]\n",
    "test_target = target[test_idx[0]:test_idx[1]]\n",
    "\n",
    "modelpath = \"my_model.h5\"\n",
    "hist = model.fit (\n",
    "    train [in_idx[0]:in_idx[1]],\n",
    "    target[in_idx[0]:in_idx[1]],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=True,\n",
    "    validation_data=(test_train, test_target)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T14:26:44.310473Z",
     "start_time": "2017-07-03T14:26:44.091326Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Give the model the data that it did not train on and ask the model to predict it.\n",
    "predictions = model.predict(train, batch_size=batch_size)\n",
    "test_pred   = predictions[test_idx[0]:test_idx[1]]\n",
    "\n",
    "print(\"Discrete Accuracy: {}\".format(\n",
    "    metrics.discrete_accuracy_all(\n",
    "        test_train,\n",
    "        test_pred,\n",
    "        test_target,\n",
    "        padding=True\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T14:32:59.286564Z",
     "start_time": "2017-07-03T14:32:58.992244Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a prediction with event number being *event_number*.\n",
    "# Event with most tracks: 3435 (21 tracks)\n",
    "# Events with >19 tracks: 130, 282, 1080, 3023, 3178, 3435, 3445, 3527\n",
    "# Events with 2 tracks: 11, 761, 1238\n",
    "# Event with 1 track: 292, 2415, 3313, 3390\n",
    "# No events have 0 tracks.\n",
    "event_number = 3178\n",
    "\n",
    "print(\"Event {}\".format(event_number))\n",
    "\n",
    "print(metrics.discrete_accuracy(\n",
    "    train[event_number],\n",
    "    predictions[event_number],\n",
    "    target[event_number],\n",
    "    padding=True\n",
    "))\n",
    "\n",
    "utils.plot3d(\n",
    "    train[event_number],\n",
    "    target[event_number],\n",
    "    target[event_number],\n",
    "    order=ORDERING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the prediction compared to the target matrix.\n",
    "utils.display_side_by_side(\n",
    "    train[event_number],\n",
    "    target[event_number],\n",
    "    predictions[event_number],\n",
    "    order=ORDERING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-03T14:28:02.941196Z",
     "start_time": "2017-07-03T14:28:02.588957Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a history of losses and accuracy that the model calculated\n",
    "# during the fitting process.\n",
    "utils.print_scores(model, train, target, batch_size)\n",
    "utils.graph_losses([(\"Categorical Cross Entropy\", hist)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
