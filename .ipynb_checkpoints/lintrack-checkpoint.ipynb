{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a program that will train a model to identify and assign hits to tracks.\n",
    "Written by Daniel Zurawski & Keshav Kapoor for Fermilab Summer 2017 internship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is borrowed from a DS&HEP tutorial.\n",
    "It is used to graph the histories after fitting a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_losses( histories ):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    #plt.ylim(bottom=0)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Error by Epoch')\n",
    "    colors=[]\n",
    "    do_acc=False\n",
    "    for label,loss in histories:\n",
    "        color = tuple([0.1, 0.1, 0.1])\n",
    "        colors.append(color)\n",
    "        l = label\n",
    "        vl= label+\" validation\"\n",
    "        if 'acc' in loss.history:\n",
    "            l+=' (acc %2.4f)'% (loss.history['acc'][-1])\n",
    "            do_acc = True\n",
    "        if 'val_acc' in loss.history:\n",
    "            vl+=' (acc %2.4f)'% (loss.history['val_acc'][-1])\n",
    "            do_acc = True\n",
    "        plt.plot(loss.history['loss'], label=l, color=color)\n",
    "        if 'val_loss' in loss.history:\n",
    "            plt.plot(loss.history['val_loss'], lw=2, ls='dashed', label=vl, color=color)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    if not do_acc: return\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    for i,(label,loss) in enumerate(histories):\n",
    "        color = colors[i]\n",
    "        if 'acc' in loss.history:\n",
    "            plt.plot(loss.history['acc'], lw=2, label=label+\" accuracy\", color=color)\n",
    "        if 'val_acc' in loss.history:\n",
    "            plt.plot(loss.history['val_acc'], lw=2, ls='dashed', label=label+\" validation accuracy\", color=color)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a LinearTracker class.\n",
    "This class is used to load input and output from a .csv file in the correct format for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearTracker():\n",
    "    \"\"\" An object that classifies particles to tracks after an event. \"\"\"    \n",
    "    def __init__(self, dataframe, model=None):\n",
    "        \"\"\" Initialize a LinearTracker.\n",
    "            @param dataframe - pd.DataFrame - used to pick tracks from.\n",
    "                The headers should contain: (\"id\", \"z\", \"r\", \"phi\").\n",
    "            @param model - keras model - A network model that the tracker will\n",
    "                use to classify particles.\n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.model     = model     # keras model to figure out tracks.\n",
    "        self.dataframe = dataframe # pandas.DataFrame for picking tracks.\n",
    "        self.input     = None      # input to train model on.\n",
    "        self.output    = None      # output to train model on.\n",
    "    # END function __init__\n",
    "    \n",
    "    def load_data(self, num_events,\n",
    "                  tracks_per_event, track_size, noise_per_event):\n",
    "        \"\"\" Load input and output data from this object's dataframe.\n",
    "            @param num_events - int - The number of events to generate.\n",
    "            @param tracks_per_event - int - The number of tracks per event.\n",
    "            @param track_size - int - The number of hits per track.\n",
    "            @param noise_per_event - int - The number of hits with no track.\n",
    "            @return Nothing\n",
    "                However, self.input and self.output become numpy arrays.\n",
    "                self.input is collection of hits of shape:\n",
    "                    (num_events, hits_per_event, 3)\n",
    "                self.output is list of probability matrices of shape:\n",
    "                    (num_events, hits_per_event, tracks_per_event)\n",
    "        \"\"\"\n",
    "        hits_per_event = (track_size * tracks_per_event) + noise_per_event\n",
    "        data   = self.dataframe[[\"id\", \"r\", \"phi\", \"z\"]].drop_duplicates()\n",
    "        groups = data.groupby(\"id\")\n",
    "        valids = groups.filter(lambda track: len(track) == track_size)\n",
    "        bads   = groups.filter(lambda track: len(track) != track_size)\n",
    "        labels = [\"phi\", \"r\", \"z\"]\n",
    "        \n",
    "        # Populate input and output with data.\n",
    "        self.input  = np.zeros((num_events, hits_per_event, len(labels)))\n",
    "        self.output = np.zeros((num_events, hits_per_event, tracks_per_event))\n",
    "        for n in range(num_events):\n",
    "            # Retrieve the hits within this event.\n",
    "            sample = random.sample(list(valids.groupby(\"id\")), tracks_per_event)\n",
    "            tracks = [track[1] for track in sample] # Make it not a tuple.\n",
    "            noise  = bads.sample(noise_per_event)\n",
    "            hits   = pd.concat(tracks + [noise])\n",
    "            hits.sort_values(labels, inplace=True)\n",
    "            \n",
    "            # Populate this event's inputs.\n",
    "            self.input[n, :] = hits[labels].values\n",
    "            \n",
    "            # Define a mapping from track ID to probability matrix column.\n",
    "            T2I = dict()\n",
    "            for t, track_ID in enumerate([s[0] for s in sample]):\n",
    "                T2I[track_ID] = t\n",
    "            \n",
    "            # Populate this event's outputs.\n",
    "            for t, track_ID in enumerate(hits[\"id\"]):\n",
    "                index = T2I.get(track_ID)\n",
    "                if index is not None:\n",
    "                    self.output[n, t, index] = 1\n",
    "    # END FUNCTION load_data\n",
    "# END CLASS LinearTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how to create a LinearTracker and how to load data into it. It is important to note that after construction, a LinearTracker must call its load_data() function with user specifications for how data should be loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a ValueError describing how the population is not large enough for the sample, then that means that the data\n",
    "loaded in from the .csv file does not contain enough tracks of size 'track_size'. Try to either load in a larger\n",
    "population or change the 'track_size' variable to a different positive integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename  = ('linear_data_5k.csv')\n",
    "dataframe = pd.read_csv(filename)\n",
    "tracker   = LinearTracker(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into the input and output member variables of LinearTracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "tracker.load_data(num_events=30, tracks_per_event=5, track_size=4, noise_per_event=5)\n",
    "print(\"Ding! All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the input and output training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,HTML\n",
    "\n",
    "def multi_column_df_display(list_dfs, cols=2):\n",
    "    \"\"\" Code by David Medenjak responding to StackOverflow question found here:\n",
    "        https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side\n",
    "        Displays a list of dataframes in IPython as a table with cols number of columns.\n",
    "    \"\"\"\n",
    "    html_table = \"<table style='width:100%; border:0px'>{content}</table>\"\n",
    "    html_row = \"<tr style='border:0px'>{content}</tr>\"\n",
    "    html_cell = \"<td style='width:{width}%;vertical-align:top;border:0px'>{{content}}</td>\"\n",
    "    html_cell = html_cell.format(width=100/cols)\n",
    "\n",
    "    cells = [ html_cell.format(content=df.to_html()) for df in list_dfs ]\n",
    "    cells += (cols - (len(list_dfs)%cols)) * [html_cell.format(content=\"\")] # pad\n",
    "    rows = [ html_row.format(content=\"\".join(cells[i:i+cols])) for i in range(0,len(cells),cols)]\n",
    "    display(HTML(html_table.format(content=\"\".join(rows))))\n",
    "\n",
    "input_cols  = [\"phi\", \"r\", \"z\"]\n",
    "output_cols = [\"T{}\".format(i) for i in range(tracker.output.shape[2])]\n",
    "\n",
    "input_frames  = [pd.DataFrame(data=matrix, columns=input_cols)  for matrix in tracker.input]\n",
    "output_frames = [pd.DataFrame(data=matrix, columns=output_cols) for matrix in tracker.output]\n",
    "\n",
    "df_list = []\n",
    "for i in range(max(len(input_frames), len(output_frames))):    \n",
    "    df_list.append(input_frames[i])\n",
    "    df_list.append(output_frames[i])\n",
    "\n",
    "multi_column_df_display(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to load a model into our tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tracker.input[0].shape # Shape of an event.\n",
    "output_shape = tracker.output[0][0].shape[0] # Number of tracks per event\n",
    "kinit = 'uniform' # kernel_initializer\n",
    "act   = 'relu' # activation\n",
    "\n",
    "tracker.model = Sequential()\n",
    "tracker.model.add(Dense(100, input_shape=input_shape, kernel_initializer=kinit, activation=act))\n",
    "#tracker.model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2))\n",
    "#tracker.model.add(Dense(25, kernel_initializer=kinit, activation=act))\n",
    "tracker.model.add(Dense(output_shape, kernel_initializer=kinit, activation=act))\n",
    "tracker.model.add(Activation('softmax'))\n",
    "tracker.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "tracker.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "hist = tracker.model.fit(tracker.input, tracker.output, epochs=100, batch_size=batch_size,\n",
    "                         verbose=0, validation_split=0.2,\n",
    "                         callbacks=[keras.callbacks.ModelCheckpoint(filepath='simple.h5', verbose=0)])\n",
    "print(\"Ding! All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to graph the history of the nueral network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = tracker.model.evaluate(tracker.input, tracker.output, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "show_losses([(\"categorical cross entropy\", hist)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
